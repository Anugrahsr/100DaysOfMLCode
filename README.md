# #100DaysOfMLCode
>Features my daily progress on the 100DaysOfMLCode challenge on Twitter!!

## Day 1
Completed learning the basics of few Data Science libraries namely numpy, pandas, matplotlib , seaborn and was successfully able to implement them with  a few exercises by Jose Portilla. From tomorrow i'm going to focus mainly on ML. Let's see how it goes :)

Ps : I was busy contributing on an Open Source Project (Cleanpy) (which you can check out in my repo) causing a slight delay in updating the status.

<img src="./Images/1.png" width="400" height="340">  <img src="./Images/2.png" width="450" height="340">

## Day 2 & 3
Studied the univariate linear regression model and developed the intuition of how the gradient descent can used to solve any general hypothesis. And also got my linear algebra basics revised. Loving the Stanford's ML course on Coursera. Highly recommended for getting to know the mathematics behind ML !!

## Day 4
Learnt the normal equation method for solving linear regression models and also vectorisation of the Learning algorithms so as to efficiently implement in any programming Language. I also did learn the syntax and did few implementations of the algorithms in the Octave/ MATLAB programming language.

## Day 5
Finished reading the logistic regression and its vectorised implementation and also learnt how to to apply more advanced optimization algorithms like BFGS,L-BFGS in Octave. Also took time to develop the intuition of Neural networks.Today was so mentally exhausting. Still trying to digest the linear algebra of the sigmoid activation function of artificial neural network. Let's call it a day!!

## Day 6
Studied the regularization method to dilute the overfitting problem and also learned the forward and back propagation  algorithm in neural networks and how gradient descent is used to solve them. Still trying to digest the information crunch on theneural networks and its learning algorithms. Neural networks as of now seem to be slightly complicated.Today is'nt a productive day for me, but none is for everyone everyday right ??
Gonna try to gain a better intuition 'bout it tomorrow.

## Day 7 8 9
I have been travelling a lot recently due to unavoidable reasons but still took time to work on ML and cleared the Neural Network misclarification (Still working on vectorized implementation though) and also successfully submitted the second week assignment. Yayy !!

## Day 10 & 11
Finished the Week 3 assignment and started working on the neural network assignment (Let's see how it goes).ML is intriguing and fun (when we get the correct answers only). Loving this roller coaster ride !ðŸ˜€
Still struggling to find the time to work more efficiently as possible due to the untimely travel 

## Day 12 13 14 15
And it's a wrap for neural network assignment and understanding. I have been working on Adobe After effects recently so it took me time to complete the assignment and completely absorb the info crunch. What an end for the fabulous year it has been !!
Made new friends, memories, emotions, few skills and mistakes in this journey of unraveling myself !! I' ll continue to update my journey in the upcoming year too ðŸ˜‚ until then 2020 here I come and remember I will keep on failimg forward more than ever!!

## Day 16 - 20
Spent the last week revising my ML notes and also started working on the next week's assignment on error metrics and basis/variance concepts. Still tweaking the handwritten image classifier and completely awestruck of how it works and at the same time that I can implement it makes it much more cool ðŸ˜‚

## Day 20 - 23
Shifted my focus towards Computer Vision for change in topic. Finished the basics of images and basic image operations as rootating images, drawing on them etc.

## Day 24 - 27
Its been a while since i last updated but from now on I'll try to  update frequentishly ðŸ™ƒ. Completed reading the SVM model, the kernels & its mathematical intuition. I will start focusing on unsupervised learning from tomorrow and wrap up supervised Learning

## Day 28 - 30
Finished the SVM assignment and started learning about K - means algorithm and Principal Component Analysis. Also got to know about Dimensionality reduction and data compression and how PCA is used to accomplish it. Next up recommender Systems.

## Day 30 - 32
Finished K-means and PCA assignment. Finished reading Anomaly detection algorithm and how its different from supervised learning. Also read about content based recommender system. Next up Collabrative filtering.
